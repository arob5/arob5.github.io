<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2024-09-28">
<meta name="description" content="MCMC with an unbiased density approximation.">

<title>Pseudo-Marginal MCMC – Andrew G. Roberts</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-6bd9cfa162949bde0a231f530c97869d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Andrew G. Roberts</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Pseudo-Marginal MCMC</h1>
            <p class="subtitle lead">Pseudo-Marginal MCMC</p>
                  <div>
        <div class="description">
          MCMC with an unbiased density approximation.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">MCMC</div>
                <div class="quarto-category">Sampling</div>
                <div class="quarto-category">Computational Statistics</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">September 28, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>Pseudo-marginal Markov chain Monte Carlo (MCMC) is a variant of the Metropolis-Hastings algorithm that works without the ability to evaluate the unnormalized target density, so long as an unbiased sample of this density can be obtained for any input. In this post, we motivate the algorithm by considering a problem of Bayesian inference where the likelihood function is intractable. We then take a step back to understand why the algorithm works, and discuss the method from a more generic and rigorous viewpoint.</p>
<section id="pseudo-marginal-mcmc-for-bayesian-inference" class="level2" data-number="0.1">
<h2 data-number="0.1" class="anchored" data-anchor-id="pseudo-marginal-mcmc-for-bayesian-inference"><span class="header-section-number">0.1</span> Pseudo-Marginal MCMC for Bayesian Inference</h2>
<p>We start by considering a standard problem of Bayesian inference for a parameter of interest <span class="math inline">\(u \in \mathcal{U}\)</span>. Given a prior density <span class="math inline">\(\pi_0(u)\)</span> and likelihood function <span class="math inline">\(L(u)\)</span>, the unnormalized posterior density is then obtained as the product of these two quantities: <span class="math display">\[
\pi(u) := \pi_0(u) L(u). \tag{1}
\]</span> With the ability to evaluate this unnormalized density, MCMC algorithms can be applied to obtain samples from the posterior distribution. However, suppose we face a situation where <span class="math inline">\(L(u)\)</span> is intractable in the sense that it does not admit an analytic expression that can be computed for any <span class="math inline">\(u\)</span>. Suppose, though, that we can draw an unbiased sample of the quantity <span class="math inline">\(L(u)\)</span> for any input <span class="math inline">\(u\)</span>; that is, <span class="math display">\[
\begin{align}
&amp;\ell \sim P(u, \cdot), &amp;&amp;\mathbb{E}[\ell] = L(u), \tag{2}
\end{align}
\]</span> where <span class="math inline">\(P(u,\cdot)\)</span> is a probability measure on the sample space <span class="math inline">\([0, \infty)\)</span> for each <span class="math inline">\(u \in \mathcal{U}\)</span> (formally, we can think of <span class="math inline">\(P\)</span> as a Markov kernel). It turns out that this is sufficient to define an MCMC algorithm with target distribution equal to <span class="math inline">\(u\)</span>’s posterior. The algorithm that accomplishes this is referred as <em>pseudo-marginal MCMC</em>. A single step of this algorithm is detailed below.</p>
<blockquote class="blockquote">
<p>
</p><p><strong>Pseudo-Marginal MCMC.</strong> Let <span class="math inline">\(u\)</span> be the current state of the algorithm, with <span class="math inline">\(\ell \sim P(u,\cdot)\)</span> the associated unbiased likelihood sample. Let <span class="math inline">\(Q\)</span> denote the proposal kernel. The next state is then determined as follows. <br></p>
<ol type="1">
<li>Propose a new state: <span class="math display">\[
  \tilde{u} \sim Q(u, \cdot) \tag{3}
  \]</span></li>
<li>Draw an unbiased likelihood sample at the proposed state: <span class="math display">\[
  \tilde{\ell} \sim P(\tilde{u}, \cdot) \tag{4}
  \]</span></li>
<li>With probability <span class="math display">\[
  \alpha(u,\ell; \tilde{u},\tilde{\ell}) := \min\left(1, \frac{\pi_0(\tilde{u})\tilde{\ell}q(\tilde{u},u)}{\pi_0(u)\ell q(u,\tilde{u})} \right), \tag{5}
  \]</span> set the new state to <span class="math inline">\(\tilde{u}\)</span>. Else set it to the current state <span class="math inline">\(u\)</span>.
<p></p>
</li></ol></blockquote>

<p>Notice that the acceptance probability (5) is the typical Metropolis-Hastings acceptance probability but with the unbiased likelihood samples <span class="math inline">\(\ell\)</span> and <span class="math inline">\(\tilde{\ell}\)</span> inserted in place of <span class="math inline">\(L(u)\)</span> and <span class="math inline">\(L(\tilde{u})\)</span>, respectively. The claim is that this algorithm defines a Markov chain with invariant distribution <span class="math inline">\(\pi\)</span>. To see why this is true, the trick is to view the above algorithm as a Metropolis-Hastings scheme operating on the extended state vector <span class="math inline">\((u, \ell)\)</span>. In showing this, I will assume <span class="math inline">\(P(u,\cdot)\)</span> and <span class="math inline">\(Q(u,\cdot)\)</span> admit densities <span class="math inline">\(p(u,\cdot)\)</span> and <span class="math inline">\(q(u,\cdot)\)</span> with respect to the same base measure for which <span class="math inline">\(\pi\)</span> is a density (typically, the Lebesgue or counting measure). Now, to view the above algorithm with respect to the extended state space, start by noticing that (3) and (4) can be interpreted as a joint proposal <span class="math display">\[
(\tilde{u},\tilde{\ell}) \sim \overline{Q}(u,\ell; \cdot, \cdot), \tag{6}
\]</span> with <span class="math inline">\(\overline{Q}\)</span> a Markov kernel on the product space <span class="math inline">\(\mathcal{U} \times [0,\infty)\)</span> with density <span class="math display">\[
\overline{q}(u,\ell; \tilde{u},\tilde{\ell}) := q(u,\tilde{u})p(\tilde{u},\tilde{\ell}). \tag{7}
\]</span> Notice that <span class="math inline">\(\overline{Q}(u,\ell; \cdot, \cdot)\)</span> is independent of <span class="math inline">\(\ell\)</span>. It now remains to write the acceptance probability (5) in a form that can be interpreted with respect to the extended state space. To this end, consider <span class="math display">\[
\begin{align}
\frac{\pi_0(\tilde{u})\tilde{\ell}q(\tilde{u},u)}{\pi_0(u)\ell q(u,\tilde{u})}
&amp;= \frac{\pi_0(\tilde{u})\tilde{\ell}}{\pi_0(u)\ell}
\cdot \frac{q(\tilde{u},u)p(u,\ell)}{q(u,\tilde{u})p(\tilde{u},\tilde{\ell})}
\cdot \frac{p(\tilde{u},\tilde{\ell})}{p(u,\ell)} \newline
&amp;= \frac{\pi_0(\tilde{u})\tilde{\ell}p(\tilde{u},\tilde{\ell})}{\pi_0(u)\ell p(u,\ell)}
\cdot \frac{\overline{q}(\tilde{u},\tilde{\ell};u,\ell)}{\overline{q}(u,\ell;\tilde{u},\tilde{\ell})}. \tag{8}
\end{align}
\]</span> The second term is the proposal density ratio with respect to extended proposal <span class="math inline">\(\overline{q}\)</span>. Thus, the function appearing in the numerator and denominator of the first term must be the (unnormalized) density targeted by this Metropolis-Hastings scheme. In other words, the invariant distribution implied by the above algorithm has unnormalized density <span class="math display">\[
\overline{\pi}(u,\ell) := \pi_0(u)p(u,\ell)\ell. \tag{9}
\]</span> Notice that <span class="math inline">\(\pi_0(u)\ell\)</span> is the unnormalized density (1) with the sample <span class="math inline">\(\ell\)</span> inserted in place of <span class="math inline">\(L(u)\)</span>. This is multiplied by the weight <span class="math inline">\(p(u,\ell)\)</span>, which encodes the probability of sampling <span class="math inline">\(\ell\)</span> at the input <span class="math inline">\(u\)</span>. Our proof of the algorithm’s correctness is concluded by noting that <span class="math inline">\(\overline{\pi}\)</span> admits <span class="math inline">\(\pi\)</span> as a marginal distribution; indeed, <span class="math display">\[
\begin{align}
\int \overline{\pi}(u,\ell)d\ell
&amp;= \int \pi_0(u)p(u,\ell)\ell d\ell
= \pi_0(u) \int \ell \cdot p(u,\ell) d\ell
= \pi_0(u) \mathbb{E}[\ell|u]
= \pi_0(u) L(u), \tag{10}
\end{align}
\]</span> following from the unbiasedness of the likelihood sample. This means that, in theory, we can run the above algorithm to obtain joint samples <span class="math inline">\((u,\ell) \sim \overline{\pi}\)</span>, and then simply extract the <span class="math inline">\(u\)</span> portion of these pairs to obtain the desired draws <span class="math inline">\(u \sim \pi\)</span>. One last thing to note is that we don’t actually need to be able to evaluate the density <span class="math inline">\(p(u,\ell)\)</span> appearing in (8); we see in the acceptance probability (5) that we need only be able to sample from <span class="math inline">\(P(u,\cdot)\)</span>. As usual, we need to be able to evaluate the density <span class="math inline">\(q(u,\tilde{u})\)</span>.</p>
</section>
<section id="a-more-generic-formulation" class="level2" data-number="0.2">
<h2 data-number="0.2" class="anchored" data-anchor-id="a-more-generic-formulation"><span class="header-section-number">0.2</span> A More Generic Formulation</h2>
<p>We introduced the pseudo-marginal algorithm above in the context of Bayesian inference, where the random variable <span class="math inline">\(\ell \sim P(u,\cdot)\)</span> provides an unbiased estimate of the likelihood <span class="math inline">\(L(u)\)</span>. This idea of course extends beyond the Bayesian example, for sampling from a generic target distribution with unnormalized density <span class="math inline">\(\pi(u)\)</span>. The pseudomarginal method can be applied provided access to a non-negative, unbiased estimator of <span class="math inline">\(\pi(u)\)</span>. Let’s denote this estimator by <span class="math inline">\(\hat{\pi}(u; x)\)</span>, where <span class="math inline">\(x \sim h\)</span>. In constrast to the presentation above, we now suppose the randomness in the estimator stems from an underlying random variable <span class="math inline">\(x\)</span> that is independent of <span class="math inline">\(u\)</span>. The dependence on <span class="math inline">\(u\)</span> still shows up in <span class="math inline">\(\hat{\pi}(u; x)\)</span>, so this is essentially a different way of thinking of the same algorithm. As before, we target the extended distribution <span class="math display">\[
\begin{equation}
\overline{\pi}(u, x) := \hat{\pi}(u;x)h(x) \tag{11}
\end{equation}
\]</span> and consider a proposal of the form <span class="math display">\[
\begin{equation}
\overline{q}(u,x; \tilde{u}, \tilde{x})
:= q(u,\tilde{u})h(\tilde{x}). \tag{12}
\end{equation}
\]</span> The Metropolis-Hastings acceptance ratio then simplifies to <span class="math display">\[
\begin{equation}
\frac{\hat{\pi}(\tilde{u};\tilde{x})h(\tilde{x}) q(\tilde{u},u) h(x)}
{\hat{\pi}(u;x)h(x) q(u, \tilde{u}) h(\tilde{x})}
= \frac{\hat{\pi}(\tilde{u};\tilde{x}) q(\tilde{u},u)}
{\hat{\pi}(u;x) q(u, \tilde{u})}. \tag{13}
\end{equation}
\]</span></p>
<p>We have thus again constructed an implementable MCMC algorithm with the correct invariant distribution.</p>
<section id="efficiency" class="level3" data-number="0.2.1">
<h3 data-number="0.2.1" class="anchored" data-anchor-id="efficiency"><span class="header-section-number">0.2.1</span> Efficiency</h3>
<p>Despite being correct, pseudo-marginal schemes are known to suffer from poor efficiency when the variance of the estimator <span class="math inline">\(\hat{\pi}(u;x)\)</span> is high. This is due to the fact that the value of <span class="math inline">\(x\)</span> in the algorithm is only updated when a new value of <span class="math inline">\(u\)</span> is accepted. If <span class="math inline">\(\hat{\pi}(u;x)\)</span> is quite variable, then a value of <span class="math inline">\(x\)</span> may be sampled such that <span class="math inline">\(\hat{\pi}(u;x)\)</span> significantly overestimates <span class="math inline">\(\pi(u)\)</span>. It therefore might take many iterations to sample a new value <span class="math inline">\(\tilde{x}\)</span> that allows <span class="math inline">\(\hat{\pi}(u;\tilde{x})\)</span> to compete with <span class="math inline">\(\hat{\pi}(u;x)\)</span> in the acceptance ratio. <span class="citation" data-cites="corrPM">Deligiannidis, Doucet, and Pitt (<a href="#ref-corrPM" role="doc-biblioref">2017</a>)</span> reports that this behavior can typically be avoided by ensuring that the variance of <span class="math inline">\(\log \hat{\pi}(u;x)\)</span> stays between <span class="math inline">\(1\)</span> and <span class="math inline">\(3\)</span> in regions of high probability.</p>
<p>In practice, one commonly has control over the variance of the estimator but reducing the variance comes at the cost of increased computational expense per iteration. A typical example is where <span class="math inline">\(x = x_{1:n}\)</span> represents <span class="math inline">\(n\)</span> samples <span class="math inline">\(x_i \overset{\text{ind}}{\sim} h_i\)</span>, <span class="math inline">\(h(x) = \prod_{i=1}^{n} h_i(x)\)</span>, and <span class="math inline">\(\hat{\pi}(u;x) = \frac{1}{n} \sum_{i=1}^{n} \hat{\pi}(u;x_i)\)</span> is a sample mean. One can therefore reduce the variance of the estimator by increasing the number of samples used to compute the mean.</p>
</section>
</section>
<section id="the-correlated-psuedo-marginal-method" class="level2" data-number="0.3">
<h2 data-number="0.3" class="anchored" data-anchor-id="the-correlated-psuedo-marginal-method"><span class="header-section-number">0.3</span> The Correlated Psuedo-marginal Method</h2>
<p><span class="citation" data-cites="corrPM">Deligiannidis, Doucet, and Pitt (<a href="#ref-corrPM" role="doc-biblioref">2017</a>)</span> present an alternative method for variance reduction that does not require as large of a sample size to achieve a given variance level. The idea stems from the fact that it is really the variability in the acceptance ratio that determines the efficiency of the algorithm. Therefore, we can consider methods for reducing the variance of the ratio estimator <span class="math inline">\(\hat{\pi}(u;\tilde{x}) / \hat{\pi}(u;x)\)</span>. In general, ratio estimators have lower variance when the numerator and denominator are positively correlated. In the pseudo-marginal method, the variable <span class="math inline">\(\tilde{x}\)</span> is sampled from <span class="math inline">\(h\)</span> independently of <span class="math inline">\(x\)</span>, implying independence between <span class="math inline">\(\hat{\pi}(u;\tilde{x})\)</span> and <span class="math inline">\(\hat{\pi}(u;x)\)</span>.</p>
<p>Instead of sampling the values of <span class="math inline">\(x\)</span> independently, we might instead consider allowing the values to follow a Markov chain in order to induce correlation between the numerator and denominator in the acceptance ratio. We are still targeting the joint distribution <span class="math inline">\(\overline{\pi}(u, x) := \hat{\pi}(u;x)h(x)\)</span>, but we now weaken the requirement that <span class="math inline">\(\tilde{x}\)</span> be sampled directly from <span class="math inline">\(h\)</span>. Suppose instead that <span class="math inline">\(\tilde{x}\)</span> is sampled from a <span class="math inline">\(h\)</span>-reversible Markov kernel <span class="math inline">\(P(x,\cdot)\)</span> with density <span class="math inline">\(p(x, \cdot)\)</span>; that is, <span class="math display">\[
h(x)p(x, \tilde{x}) = h(\tilde{x})p(\tilde{x}, x). \tag{14}
\]</span> We apply (14) to simplify the acceptance ratio as <span class="math display">\[
\begin{align}
\frac{\hat{\pi}(\tilde{u}, \tilde{x}) q(\tilde{u},u) h(\tilde{x}) p(\tilde{x},x)}
{\hat{\pi}(u; x) q(u, \tilde{u}) h(x)p(x, \tilde{x})}
&amp;= \frac{\hat{\pi}(\tilde{u}, \tilde{x}) q(\tilde{u},u) h(x)p(x, \tilde{x})}
{\hat{\pi}(u; x) q(u, \tilde{u}) h(x)p(x, \tilde{x})} \\
&amp;= \frac{\hat{\pi}(\tilde{u}, \tilde{x}) q(\tilde{u},u)}
{\hat{\pi}(u; x) q(u, \tilde{u})}. \tag{15}
\end{align}
\]</span> The acceptance ratio is exactly as in the standard pseudo-marginal method. Note also that the choice <span class="math inline">\(p(x, \cdot) = h(\cdot)\)</span> recovers the previous algorithm.</p>
<section id="estimators-based-on-gaussian-random-variables" class="level3" data-number="0.3.1">
<h3 data-number="0.3.1" class="anchored" data-anchor-id="estimators-based-on-gaussian-random-variables"><span class="header-section-number">0.3.1</span> Estimators based on Gaussian Random Variables</h3>
<p>The key to implementing this method is to define a valid <span class="math inline">\(h\)</span>-reversible Markov kernel <span class="math inline">\(P\)</span>. In general, this will be somewhat problem-specific, but many estimators <span class="math inline">\(\hat{\pi}(u; x)\)</span> can be written as a suitable transformation of a Gaussian random variable <span class="math inline">\(x \sim \mathcal{N}(m, C)\)</span>. <span class="citation" data-cites="corrPM">Deligiannidis, Doucet, and Pitt (<a href="#ref-corrPM" role="doc-biblioref">2017</a>)</span> focus exclusively on this setting. A well-known method for constructing a <span class="math inline">\(\mathcal{N}(m, C)\)</span>-reversible kernel is via a preconditioned Crank-Nicholson (pCN) update <span class="math display">\[
\begin{equation}
\tilde{x} := m + \rho(x-m) + \sqrt{1 - \rho^2} \xi,
\qquad \xi \sim \mathcal{N}(0, C), \tag{16}
\end{equation}
\]</span> implying the kernel <span class="math display">\[
\begin{equation}
p(x, \tilde{x}) = \mathcal{N}(\rho x + (1-\rho)m, (1-\rho^2)C). \tag{17}
\end{equation}
\]</span> To see that <span class="math inline">\(P\)</span> is reversible (and thus invariant) with respect to <span class="math inline">\(\mathcal{N}(m, C)\)</span>, notice that (16) implies the joint distribution <span class="math display">\[
\begin{equation}
\begin{bmatrix} x \\ \tilde{x} \end{bmatrix} \sim
\mathcal{N}\left(
\begin{bmatrix} m \\ m \end{bmatrix},
\begin{bmatrix} C &amp; \rho C \\ \rho C &amp; C \end{bmatrix}
\right), \tag{18}
\end{equation}
\]</span> which satisfies <span class="math inline">\((x,\tilde{x}) \overset{d}{=} (\tilde{x},x)\)</span> and hence <span class="math inline">\(P\)</span> satisfies (17).</p>
<div class="callout callout-style-default callout-note callout-titled" title="Proof">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Proof
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Since <span class="math inline">\((x,\tilde{x})\)</span> is a linear combination of the independent Gaussian variables <span class="math inline">\(x\)</span> and <span class="math inline">\(\xi\)</span>, it is itself Gaussian distributed. The moments of the <span class="math inline">\(x\)</span> marginal are already known, and the remaining moments can be filled in by noting <span class="math display">\[\begin{align}
\mathbb{E}[\tilde{x}]
&amp;= m + \rho(\mathbb{E}[x]-m) + \sqrt{1 - \rho^2} \mathbb{E}[\xi] = m \\
\mathrm{Cov}[\tilde{x}]
&amp;= \rho^2 \mathrm{Cov}[x-m] + (1-\rho^2)\mathrm{Cov}(\xi) = C \\
\mathrm{Cov}[x,\tilde{x}]
&amp;= \mathrm{Cov}[x,\rho x + \sqrt{1 - \rho^2}\xi]
= \rho \mathrm{Cov}[x] + \sqrt{1-\rho^2}\mathrm{Cov}[x,\xi] = \rho C.
\end{align}\]</span></p>
<p>Notice that <span class="math inline">\((x,\tilde{x}) \sim h(dx)P(x,d\tilde{x})\)</span>. Therefore, the fact that <span class="math inline">\((x,\tilde{x})\)</span> and <span class="math inline">\((\tilde{x},x)\)</span> are equal in distribution implies the reversibility condition <span class="math inline">\(h(dx)P(x,d\tilde{x}) = h(d\tilde{x})P(\tilde{x},dx)\)</span>. Reversibility is a sufficient condition for invariance, and thus <span class="math inline">\(h(dx)P(x,d\tilde{x}) = h(d\tilde{x})\)</span> also holds. <span class="math inline">\(\qquad \blacksquare\)</span></p>
</div>
</div>
</div>
<p>Notice from (18) that the tuning parameter <span class="math inline">\(\rho\)</span> controls the correlation between <span class="math inline">\(x\)</span> and <span class="math inline">\(\tilde{x}\)</span>. Since we want to induce positive correlation between these variables, <span class="math inline">\(\rho\)</span> will typically be set to a value close to one.</p>
<p>As before, this method encompasses the case where the estimator is a sample mean of the form <span class="math display">\[
\begin{equation}
\hat{\pi}(u;x) = \frac{1}{n} \sum_{i=1}^{n} \hat{\pi}(u; x_i),
\qquad x_i \overset{\mathrm{iid}}{\sim} \mathcal{N}(m_0, C_0)
\end{equation}
\]</span> where <span class="math inline">\(\mathbb{E}[\hat{\pi}(u; x_i)] = \pi(u)\)</span> for each <span class="math inline">\(x_i\)</span>. The vector <span class="math inline">\(x := [x_1, \dots, x_n]\)</span> is still Gaussian with mean <span class="math inline">\(m := [m_0, \dots, m_0]\)</span> and block-diagonal covariance <span class="math inline">\(C := \mathrm{diag}(C_0, \dots, C_0)\)</span>. In this case, the pCN update in (16) reduces to the <span class="math inline">\(n\)</span> updates <span class="math display">\[
\begin{equation}
\tilde{x}_i := m_0 + \rho(x_i - m_0) + \sqrt{1-\rho^2} \xi_i,
\qquad \xi \overset{\mathrm{iid}}{\sim} \mathcal{N}(0, C_0)
\end{equation}
\]</span> for <span class="math inline">\(i = 1, \dots, n\)</span>.</p>
</section>
</section>
<section id="being-a-bit-more-rigorous" class="level2" data-number="0.4">
<h2 data-number="0.4" class="anchored" data-anchor-id="being-a-bit-more-rigorous"><span class="header-section-number">0.4</span> Being a bit more rigorous</h2>
<p>In this section, we discuss the pseudo-marginal algorithm from a more generic perspective, and fill in some of the measure-theoretic details. Let’s assume <span class="math inline">\(\Pi\)</span> is some generic target distribution on a measurable space <span class="math inline">\((\mathcal{U}, \mathcal{B}(\mathcal{U}))\)</span>. We write <span class="math inline">\(\mathcal{B}(\mathcal{U})\)</span> to denote the Borel <span class="math inline">\(\sigma\)</span>-algebra; that is, the <span class="math inline">\(\sigma\)</span>-algebra generated by the open sets of <span class="math inline">\(\mathcal{U}\)</span>. We assume <span class="math inline">\(\Pi\)</span> admits a density (i.e., Radon-Nikodym derivative) <span class="math inline">\(\pi\)</span> with respect to some reference measure <span class="math inline">\(\nu\)</span>. The density <span class="math inline">\(\pi\)</span> need not be normalized. All densities considered throughout this section will be with respect to the same reference measure <span class="math inline">\(\nu\)</span>. As before, we consider <span class="math inline">\(\pi(u)\)</span> intractable, but assume we can draw samples from an unbiased estimator. We could define <span class="math inline">\(P(u,\cdot)\)</span> as before such that samples drawn from <span class="math inline">\(P(u,\cdot)\)</span> are unbiased with respect to <span class="math inline">\(\pi(u)\)</span>. However, note that this is equivalent to considering samples <span class="math inline">\(w \sim P(u,\cdot)\)</span> with expectation one, such that <span class="math inline">\(w \cdot \pi(u)\)</span> is unbiased for <span class="math inline">\(\pi(u)\)</span>. This seems to be a roundabout way to go around this, but for the purposes of analysis it turns out to be convenient. This is the definition used in some of the “noisy MCMC” literature (see, e.g., Medina-Aguayo et al, 2018). Thus, let’s go with this definition and define the Markov kernel <span class="math inline">\(P: \mathcal{U} \to [0,1]\)</span> such that (1) <span class="math inline">\(P(u,\cdot)\)</span> is a probability measure on <span class="math inline">\((\mathcal{W},\mathcal{B}(\mathcal{W}))\)</span> for each <span class="math inline">\(u \in \mathcal{U}\)</span>, where <span class="math inline">\(\mathcal{W} \subseteq [0,\infty)\)</span>; and (2) <span class="math inline">\(P\)</span> produces weights with unit expectation: <span class="math display">\[
\begin{align}
&amp;w \sim P(u,\cdot), &amp;&amp;\mathbb{E}_{P_u}[w] = 1. \tag{11}
\end{align}
\]</span> We use <span class="math inline">\(P_u\)</span> as shorthand for <span class="math inline">\(P(u,\cdot)\)</span> in the subscript. We again emphasize that the sample <span class="math inline">\(w\)</span> from (11) implies that <span class="math inline">\(w\pi(u)\)</span> is an unbiased estimate of <span class="math inline">\(\pi(u)\)</span>. The pseudo-marginal algorithm proceeds exactly as before. We state it again below to emphasize the new notation.</p>
<blockquote class="blockquote">
<p>
<strong>Pseudo-Marginal MCMC.</strong> <br> 1. Propose a new state: <span class="math display">\[
  \tilde{u} \sim Q(u, \cdot) \tag{12}
  \]</span> 2. Draw an unbiased weight sample at the proposed state: <span class="math display">\[
  \tilde{w} \sim P(\tilde{u}, \cdot) \tag{13}
  \]</span> 3. With probability <span class="math display">\[
  \alpha(u,w; \tilde{u},\tilde{w}) := \min\left(1, \frac{\pi(\tilde{u})\tilde{w}q(\tilde{u},u)}{\pi(u)w q(u,\tilde{u})} \right), \tag{14}
  \]</span> set the new state to <span class="math inline">\(\tilde{u}\)</span>. Else set it to the current state <span class="math inline">\(u\)</span>.
</p>
</blockquote>
<p>Of course, we can’t evaluate <span class="math inline">\(\pi(u)\)</span> in (14), but stating the algorithm this way is useful to study its properties. In practice, we can think of drawing a sample to directly approximate <span class="math inline">\(\pi(u)\)</span>. Similar to before, we can think about this algorithm as targeting an invariant distribution on the product space <span class="math inline">\((\mathcal{U} \times \mathcal{W}, \mathcal{B}(\mathcal{U}) \times \mathcal{B}(\mathcal{W}))\)</span>. The steps (12) and (13) represent a draw from the proposal kernel <span class="math inline">\(\overline{Q}: \mathcal{U} \times \mathcal{W} \to [0,1]\)</span> defined by <span class="math display">\[
\overline{Q}(u,w; U,W) := \int_{U} P(\tilde{u},W)Q(u,d\tilde{u}), \tag{15}
\]</span> for <span class="math inline">\(U \in \mathcal{B}(\mathcal{U})\)</span> and <span class="math inline">\(W \in \mathcal{B}(\mathcal{W})\)</span>.</p>
</section>
<section id="references" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> References</h1>
<ol type="1">
<li>The pseudo-marginal approach for efficient Monte Carlo computations (Andrieu and Roberts, 2009)</li>
<li>Convergence properties of pseudo-marginal Markov chain Monte Carlo algorithms (Andrieu and Vihola, 2015)</li>
<li>Stability of Noisy Metropolis-Hastings (Medina-Aguayo et al, 2018)</li>
</ol>




</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-corrPM" class="csl-entry" role="listitem">
Deligiannidis, George, Arnaud Doucet, and Michael K. Pitt. 2017. <span>“The Correlated Pseudo-Marginal Method.”</span> <a href="https://arxiv.org/abs/1511.04992">https://arxiv.org/abs/1511.04992</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>