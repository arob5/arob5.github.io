<html>
<head>
    <title>Andrew Roberts</title>
    <meta charset='UTF-8'>
    <meta content='width=device-width, initial-scale=1' name='viewport'/>

    <meta name='description' content='Andrew Roberts is a PhD candidate at Boston University.'>
    <!-- A decent browser will parse this fine:
         https://webmasters.stackexchange.com/questions/92744. -->
    <meta name='keywords' content='
        machine learning,
        inverse problems,
        data assimilation,
        dynamical systems,
        statistical machine learning,
        bayesian inference,
        statistics,
        computational statistics,
        linear algebra,
        numerical linear algebra,
        statistical software,
        deep learning,
        computer science
    '>
    <meta name='author' content='Andrew Roberts'>

    <link rel='shortcut icon' href='/favicon.png?v=e' />
    <link href='/css/blog.css' rel='stylesheet'/>

    <script type='text/x-mathjax-config'>
MathJax.Hub.Config({
  jax: ['input/TeX', 'output/HTML-CSS'],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
    extensions: ['color.js']
  },
  messageStyle: 'none',
  'HTML-CSS': { preferredFont: 'TeX', availableFonts: ['STIX','TeX'] }
});
</script>

<script src='//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML' type='text/javascript'></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
</head>
<body>
    <div class='nav'>
    <ul class='wrap'>
        <li><a href='/'>Home</a></li>
        <li><a href='/blog'>Blog</a></li>
        <li><a href='/feed.xml'>RSS</a></li>
    </ul>
</div>

    <div id='blog' class='wrap'>
        <div id='intro'>
            <div class='quote'>
                <p>Many thanks to
                <a href='https://gregorygundersen.com/' target='_blank'>Gregory Gundersen</a>
                for the
                <a href='https://gregorygundersen.com/blog/2020/06/21/blog-theme/' target='_blank'>blog theme</a>.
                </p>
            </div>
        </div>
        <div id='posts' class='section'>
            
                <div class='post-row'>
                    <p class='post-title'>
                        <a href="/blog/2024/05/30/active-subspaces/">
                            
                            Active Subspaces
                            
                        </a>
                    </p>
                    <p class='post-date'>
                        30 May 2024
                    </p>
                </div>
                <p class='post-subtitle'>
                    
                    An introduction to dimensionality reduction via active subspaces.
                    
                </p>
                <span class='hidden'>1</span>
            
                <div class='post-row'>
                    <p class='post-title'>
                        <a href="/blog/2024/05/19/Gaussian-Measures-multivariate/">
                            
                            Gaussian Measures, Part 2 - The Multivariate Case
                            
                        </a>
                    </p>
                    <p class='post-date'>
                        19 May 2024
                    </p>
                </div>
                <p class='post-subtitle'>
                    
                    A fairly deep dive into Gaussian measures in finitely many dimensions. The next step in building up to the infinite-dimensional case.
                    
                </p>
                <span class='hidden'>2</span>
            
                <div class='post-row'>
                    <p class='post-title'>
                        <a href="/blog/2024/05/16/Gaussian-measures-finite/">
                            
                            Gaussian Measures, Part 1 - The Univariate Case
                            
                        </a>
                    </p>
                    <p class='post-date'>
                        16 May 2024
                    </p>
                </div>
                <p class='post-subtitle'>
                    
                    A brief introduction to Gaussian measures in one dimension, serving to provide the setup for an extension to multiple, and eventually infinite, dimensions.
                    
                </p>
                <span class='hidden'>3</span>
            
                <div class='post-row'>
                    <p class='post-title'>
                        <a href="/blog/2024/03/24/scattered-data-approximation1/">
                            
                            An Introduction to Scattered Data Approximation
                            
                        </a>
                    </p>
                    <p class='post-date'>
                        24 March 2024
                    </p>
                </div>
                <p class='post-subtitle'>
                    
                    I summarize the first chapter of Holger Wendland's book "Scattered Data Approximation", which I augment with some background on polynomial interpolation and splines.
                    
                </p>
                <span class='hidden'>4</span>
            
                <div class='post-row'>
                    <p class='post-title'>
                        <a href="/blog/2024/03/18/outer-product/">
                            
                            Generalizing the Outer Product to Hilbert Space
                            
                        </a>
                    </p>
                    <p class='post-date'>
                        18 March 2024
                    </p>
                </div>
                <p class='post-subtitle'>
                    
                    I briefly discuss how the outer product, familiar in Euclidean space, can be viewed as a linear operator which can readily be generalized to Hilbert space.
                    
                </p>
                <span class='hidden'>5</span>
            
                <div class='post-row'>
                    <p class='post-title'>
                        <a href="/blog/2024/02/15/nonlinear-maps-of-Gaussians/">
                            
                            Approximating Nonlinear Functions of Gaussians, Part I - Linearized Kalman Filter Extensions
                            
                        </a>
                    </p>
                    <p class='post-date'>
                        15 February 2024
                    </p>
                </div>
                <p class='post-subtitle'>
                    
                    I discuss the generic problem of approximating the distribution resulting from a non-linear transformation of a Gaussian random variable, and then show how this leads to extensions of the Kalman filter which yield approximate filtering algorithms in the non-linear setting.
                    
                </p>
                <span class='hidden'>6</span>
            
                <div class='post-row'>
                    <p class='post-title'>
                        <a href="/blog/2024/02/15/Kalman-Filter/">
                            
                            The Kalman Filter - A Few Different Perspectives
                            
                        </a>
                    </p>
                    <p class='post-date'>
                        15 February 2024
                    </p>
                </div>
                <p class='post-subtitle'>
                    
                    I discuss the Kalman filter from both the Bayesian and optimization perspectives.
                    
                </p>
                <span class='hidden'>7</span>
            
                <div class='post-row'>
                    <p class='post-title'>
                        <a href="/blog/2024/01/29/Bayesian-filtering/">
                            
                            An Introduction to Bayesian Filtering and Smoothing
                            
                        </a>
                    </p>
                    <p class='post-date'>
                        29 January 2024
                    </p>
                </div>
                <p class='post-subtitle'>
                    
                    I provide an overview of the general framework for statistical filtering, viewed from the Bayesian perspective.
                    
                </p>
                <span class='hidden'>8</span>
            
                <div class='post-row'>
                    <p class='post-title'>
                        <a href="/blog/2024/01/28/Bayes-Rule/">
                            
                            The Measure-Theoretic Context of Bayes' Rule
                            
                        </a>
                    </p>
                    <p class='post-date'>
                        28 January 2024
                    </p>
                </div>
                <p class='post-subtitle'>
                    
                    I describe Bayes' rule in a measure-theoretic context, explain how it can be viewed as a non-linear operator on probability measures, and detail applications to Bayesian inverse problems.
                    
                </p>
                <span class='hidden'>9</span>
            
                <div class='post-row'>
                    <p class='post-title'>
                        <a href="/blog/2023/12/31/MH-update-from-kernel/">
                            
                            Deriving the Metropolis-Hastings Update from the Transition Kernel
                            
                        </a>
                    </p>
                    <p class='post-date'>
                        31 December 2023
                    </p>
                </div>
                <p class='post-subtitle'>
                    
                    Given only the Metropolis-Hastings transition kernel, I show how to recover the Metropolis-Hastings update rule.
                    
                </p>
                <span class='hidden'>10</span>
            
                <div class='post-row'>
                    <p class='post-title'>
                        <a href="/blog/2023/12/15/PCA/">
                            
                            Principal Components Analysis
                            
                        </a>
                    </p>
                    <p class='post-date'>
                        15 December 2023
                    </p>
                </div>
                <p class='post-subtitle'>
                    
                    I derive the PCA decomposition from both a minimum reconstruction error and maximum variance perspective. I also discuss a statistical interpretation of PCA.
                    
                </p>
                <span class='hidden'>11</span>
            
        </div>
    </div>
</body>
</html>
