---
title: Hölder Continuity and Hölder Spaces
subtitle: I introduce Hölder continuity as a generalization of Lipschitz continuity, then discuss how this can be used to define spaces of functions with useful continuity properties.
layout: default
date: 2024-03-31
keywords: Theory, Analysis
published: true
---

The notion the smoothness of a function is central in many areas of applied
mathematics and statistics. In an introductory analysis course, one typically
explores the basic notions of continuity and uniform continuity. The former
is concerned with the smoothness of a function at a particular point in the
domain of a function, and is thus a purely *local* notion of smoothness.
By contrast, uniform continuity is a property that is defined with respect
to the entire domain of a function, and hence has some *global* flavor.
In both cases, the notion of smoothness is qualitative, in the sense that
(uniform) continuity either holds or it doesn't. It is thus desirable to
introduce more *quantitative* notions of continuity; i.e., a concept of continuity
that captures different degrees of smoothness. For example, consider a
statistical regression setup where one is trying to learn a function from
a noisy set of realizations of the function at a finite set of points. Intuitively,
we would expect this problem to be harder if the latent function is more complicated;
learning highly nonlinear relationships will naturally require more data. Thus,
from a theory point of view we would like to precisely quantify this notion - how
does the learning rate depend on smoothness of the underlying function? Hölder
continuity is one of many tools that can be used to help answer questions like
these.

# Lipschitz Continuity
{% katexmm %}
Hölder continuity is a generalization of Lipschitz continuity, so we start with
the latter. Throughout this post we will let $(X, \lVert \cdot \rVert_X)$
and $(Y, \lVert \cdot \rVert_Y)$ denote two normed linear spaces, and will
be considering functions $f: X \to Y$. Notationally, we will reserve the letters
$x$, $y$, and variants of them, for elements of the respective spaces $X$ and $Y$.
Throughout most of this post we will be considering the concrete special case
of $X = \mathbb{R}^d$, equipped with the Euclidean norm, and $Y = \mathbb{R}$.
But the initial definitions are just as easy to state in the more general setting,
so we will start here.

<blockquote>
  <p><strong>Definition.</strong>
  A function $f: X \to Y$ is said to be $L$-Lipschitz continuous if
  there exists a constant $L > 0$ satisfying
  \begin{align}
  &\lVert f(x) - f(x^\prime) \rVert_Y \leq L \lVert x - x^\prime \rVert_X, &&\forall x, x^\prime \in X. \tag{1}
  \end{align}
  </p>
</blockquote>

To start organizing things in our heads, we begin by noting that Lipschitz
continuity has global flavor to it, in a similar sense as uniform continuity;
the definition requires the value of $L$ to work *for all* $x, x^\prime \in X$.
It is also giving us a more *quantitative* notion of continuity; a function
can be Lipschitz or not, but now can also have different "levels" of continuity.
Functions that satisfy (1) for smaller values of $L$ can be interpreted as
smoother than Lipschitz functions requiring a larger $L$. In the subsequent
sections, we spend a little time unpacking this definition and
exploring its implications before proceeding with the Hölder generalization.

## Some basic interpretations

### The slope of secant lines can't get arbitrarily steep
Notice that the inequality in (1) is trivially satisfied if $x = x^\prime$, so we could have
equivalently defined $L$-Lipschitz continuity by requiring that all $x \neq x^\prime$
satisfy
$$
\frac{\lVert f(x) - f(x^\prime) \rVert_Y}{\lVert x - x^\prime \rVert_X} \leq L. \tag{2}
$$
I actually find (2) a more intuitive way to introduce this concept,
since we see that the lefthand side of (2) is simply "rise over run". Indeed,
in the special case $X = Y = \mathbb{R}$, then the ratio in (2) is precisely the
slope of the secant line connecting the two points $(x, f(x))$ and
$(x^\prime, f(x^\prime))$. Thus, we conclude that to be Lipschitz,
the slope (in absolute value) of secant lines constructed between any two points on the graph of the
function must be bounded; i.e., we cannot construct a sequence
$(x_1, x^\prime_1), (x_2, x^\prime_2), \dots$ which yields secant lines that
get arbitrarily steep - there must be a uniform upper bound.
This intuition carries over to more complicated choices of $X$ and $Y$, even
though the geometric visualization does not.

### Linear bounds on how the function values can change at any point
A more general way to think about this definition is that, loosely speaking,
it is requiring that changes in the function outputs are bounded by a linear
function of changes in the function inputs. To get the point across, we might
sloppily write this as $\Delta y \leq L \Delta x$.
However, this only makes sense if the function is linear; otherwise, $\Delta y$
is completely ambiguous since the same $\Delta x = \lVert x - x^\prime \rVert_X$
can yield different $\Delta y = \lVert f(x) - f(x^\prime) \rVert_Y$, for different
choices of $x$ and $x^\prime$. But we can think of Lipschitz continuity as requiring
a linear bound like this at every point $x \in X$, with the requirement that
there exists a single $L$ large enough so that it the linear bound $L \Delta x$
does the job for every single input.

In other words, consider an arbitrary $x_0 \in X$ and let
$\Delta_{x_0}(x) := \lVert x_0 - x \rVert_X$ denote the "distance from $x_0$"
function. The Lipschitz requirement can then
sort of be written in the following "change in $y$ bounded by change in $x$" form:
\begin{align}
&\Delta_{f(x_0)}(f(x)) \leq L \Delta_{x_0}(x), && \forall x, x_0 \in X. \tag{3}
\end{align}
This might have just made things way more confusing than they need to be, but
I kind of like this way of looking at it. As before, restricting to
$X = Y = \mathbb{R}$ provides the opportunity for nice, intuitive visualization.
In this case, the idea expressed by (3) is captured by Wikipedia's
[sliding cone](https://en.wikipedia.org/wiki/Lipschitz_continuity) visualization.
In this visualization, sliding the cone corresponds to varying $x_0$ in (3).
The idea that a single linear bound $L \Delta x$ works for all $x_0$ simultaneously
is captured by the fact that the slope of the lines defining the cone don't
change as the cone slides. Note also that the "X" shape of the sliding cone
is a consequence of the *absolute value* being bounded. The condition
$\lvert f(x_0) - f(x) \rvert \leq L \lvert x_0 - x \rvert$ is
equivalent to imposing the two conditions
$$
-L \lvert x_0 - x \rvert \leq f(x_0) - f(x) \leq L \lvert x_0 - x \rvert,
$$
each corresponding to one of the lines forming the "X".

### A Worst-Case Bound
We are used to thinking about continuity as a *local* property, concerning
infinitesimally small neighborhoods around a point. It is evident that
this is not the case with Lipschitz continuity; the Lipschitz constant $L$ is
a global constant which is derived given the function's behavior across its
entire domain. In some cases, this might seem a bit unsatisfying. Imagine
a function that is mostly flat except for a quick, steep portion, that then
leads back into another flat region. In this case, the local changes in the
function values can be bounded by $0 \times \Delta x$ on the majority of
the domain. However, the function is clearly not $0$-Lipschitz since this constant
will not work for the small portion of the function that actually is changing.
Since $L$ must due the job over all of $X$, then it can be thought of as giving
a sort of "worst case" bound. This is simply the price to be paid for using
a one-number summary of the smoothness of a function over all of $X$. It is
important to keep in mind that the $L$-bound may be way too conservative
in certain regions of $X$ where the function may be much smoother. In the example
described above, this is the case in the regions where the function is flat.
In different applications, it is sometimes useful to partition $X$ and
consider the function behavior on more local scales. Taking this idea to its
logical conclusion, we might define a function to be **locally Lipschitz**
provided that for all $x \in X$ there is some neighborhood (open set containing
$x$) such that the restriction of the function to the neighborhood is Lipschitz.
In this case, each neighborhood might have a different Lipschitz constant,
with these constants providing conservative upper bounds on the function
variation restricted to their respective neighborhoods.

## How can a continuous function not be Lipshitz?


## What can we say about derivatives of Lipshitz functions?







{% endkatexmm %}
